<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Object Tracking with A-Frame</title>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.socket.io/4.5.0/socket.io.min.js"></script>

    <style>
        html, body {
            margin: 0;
            height: 100%;
            width: 100%;
            overflow: hidden;
        }
        a-scene {
            width: 100vw;
            height: 100vh;
        }
        #video-feed {
            position: absolute;
            bottom: 5%;
            right: 5%;
            width: 40vw;
            height: 30vh;
            object-fit: cover;
        }

        /* Responsive styles */
        @media (max-width: 768px) {
            #video-feed { 
                width: 90vw;
                height: 40vh;
                bottom: 2%;
                right: 2%;
            }
        }
        
        @media (min-width: 769px) and (max-width: 1024px) {
            #video-feed { 
                width: 60vw;
                height: 35vh;
            }
        }

        @media (max-width: 480px) {
            #video-feed { 
                width: 95vw;
                height: 45vh;
                bottom: 2%;
                right: 2%;
            }
        }

        /* Full screen adjustments */
        @media (orientation: landscape) {
            #video-feed {
                width: 45vw;
                height: 35vh;
            }
        }

        @media (orientation: portrait) {
            #video-feed {
                width: 80vw;
                height: 50vh;
            }
        }
    </style>
</head>
<body>
    <a-scene>
        <a-camera fov="45" look-controls="enabled: false"></a-camera>
        <a-light type="ambient" color="#ffffff"></a-light>
        <a-light type="directional" position="-1 2 1" intensity="1" color="#ffffff"></a-light>
        
        <a-box id="tracked-box" visible="false" position="0 0 0" rotation="0 45 0" scale="1.5 1.5 1.5" material="src: #myImage; color: #FFF"></a-box>
        
        <a-plane id="video-feed" width="16" height="9" position="0 3 -5" material="src: #video-texture;"></a-plane>
        
        <a-assets>
            <img id="myImage" src="./WebD_texture.jpg"/>
            <video id="video-texture" autoplay playsinline></video>
        </a-assets>
    </a-scene>

    <script>
        const socket = io('http://localhost:8086');
        socket.on('connect', function() {
            console.log('Connected to backend');
        });

        const videoElement = document.getElementById('video-texture');
        const box = document.getElementById('tracked-box');

        let lastPosition = { x: 0, y: 0, z: 0 };
        let lastUpdateTime = Date.now();
        let zValues = [];
        const zWindowMin = -5;
        const zWindowMax = 0;
        let dataTimeout = null;

        // Access the user's camera and show the video feed
        function startCamera() {
            navigator.mediaDevices.getUserMedia({
                video: { facingMode: { ideal: "environment" } }
            }).then(function(stream) {
                videoElement.srcObject = stream;
                videoElement.play();
                requestAnimationFrame(sendFrame); // Send the video frames to the backend
            }).catch(function(err) {
                alert("Camera access is required for this app to work.");
                console.error("Error accessing camera: ", err);
            });
        }

        startCamera();

        // Capture the video frame and send it to the backend every 250ms
        function sendFrame() {
            const canvas = document.createElement('canvas');
            canvas.width = videoElement.videoWidth;
            canvas.height = videoElement.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
            const frame = canvas.toDataURL('image/jpeg', 0.6);
            socket.emit('video_frame', { frame });  // Send frame to backend
            setTimeout(() => requestAnimationFrame(sendFrame), 100);
        }

        // Calculate the average z-value for smoothing
        function getAverageZ() {
            return zValues.length ? zValues.reduce((a, b) => a + b, 0) / zValues.length : 0;
        }

        // Receive updated coordinates for the box from the backend
        socket.on('update_coordinates', function(data) {
            const frameWidth = 640;
            const frameHeight = 480;

            if (data.x !== null && data.y !== null && data.z !== null) {
                const x = (data.x / frameWidth) * 10 - 5;
                const y = -(data.y / frameHeight) * 10 + 8;
                let z = (data.z * -1) / 10;

                if (z < zWindowMin || z > zWindowMax) {
                    z = getAverageZ();
                } else {
                    zValues.push(z);
                    if (zValues.length > 5) zValues.shift();
                }

                if (z > 65 && z < 10) {
                    box.setAttribute('visible', false);
                } else {
                    lastPosition = { x, y, z };
                    box.setAttribute('position', `${x} ${y} ${z}`);
                    box.setAttribute('visible', true);
                }

                clearTimeout(dataTimeout);
                lastUpdateTime = Date.now();
            }

            dataTimeout = setTimeout(() => {
                box.setAttribute('visible', false);
                lastPosition = { x: null, y: null, z: null };  // Reset last position when hiding
            }, 300);  // 1 second timeout to hide the box
        });

        // Start the video stream when the window loads
        window.onload = startCamera;
    </script>
</body>
</html>
